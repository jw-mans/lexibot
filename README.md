# ğŸ“š LexiBot â€” Document Question Answering Telegram Bot

**LexiBot** is a Telegram bot that helps you interact with your documents using **YandexGPT**.  
You can upload a document (PDF, DOCX, RTF, MD, or TXT), ask questions about its content, and the bot will answer intelligently â€” keeping conversation context between your questions.

## ğŸš€ Features

- ğŸ¤– Uses **YandexGPT** for natural language understanding and answering questions
- ğŸ“‚ Supports multiple document formats:
    - PDF (.pdf)
    - Word (.doc, .docx)
    - Rich Text (.rtf)
    - Markdown / Text (.md, .txt)
- ğŸ’¬ Remembers chat history per user for contextual conversation
- ğŸ³ Fully containerized via Docker / Docker Compose
- âš¡ Built with **Aiogram** (async Telegram bot framework)

## ğŸ§  How It Works
1) **User sends a document** to the bot.  
    The file is downloaded, parsed, and its text content is stored.

2) **User asks a question** about the document.  
The bot combines:
    - the extracted text,
    - previous conversation history,
    - and the new question,
    and sends it to **YandexGPT** via its API.

3) **Bot replies** with a generated answer and remembers the conversation for context.

## âš™ï¸ Installation and Setup
### 1) Clone the repository
```bash
git clone https://github.com/yourusername/lexibot.git
cd lexibot
```
### 2) Create a `.env` file
Inside `src/config/.env`, add your API keys and bot token:
```env
TELEGRAM_BOT_TOKEN=your_telegram_bot_token
YANDEX_API_KEY=your_yandex_api_key
YANDEX_API_KEY_ID=your_yandex_key_id
YANDEX_API_MODEL_URI=your_yandex_model_uri
YANDEX_API_URL=https://llm.api.cloud.yandex.net/foundationModels/v1/completion
YANDEX_CLOUD_CATALOG_ID=your_yandex_cloud_catalog_id
```

### 3) *Option A*: Run locally
Install dependencies and run the bot:
```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python -m src.bot.route
```
### 4) *Option B*: Run with Docker
Build and start using Docker Compose:
```bash
docker compose up --build -d
```

This will: 
- Build the bot image from `Dockerfile`

- Mount `./storage` to persist user uploads
- Start the bot container

## ğŸ’¡ Usage

Once the bot is running:

1) Open your bot on Telegram (using the bot username linked to your token).

2) Send `/start`.

3) Upload a file (PDF, DOCX, RTF, MD, or TXT).

4) Ask questions like:

    - â€œWhat is this document about?â€
    - â€œSummarize the second section.â€
    - â€œWho is mentioned as the main author?â€

The bot will answer using the uploaded documentâ€™s content and remember the chat history for follow-up questions.

## ğŸ§© Core Components
### ğŸ§¾ Document Loader

Located in `src/core/loader/`, it automatically detects file type and extracts text:

- PDFReader â€” reads PDFs with PyPDF

- DocReader â€” parses Word (.docx) files

- RTFReader â€” converts RTF to plain text

- MDReader â€” decodes Markdown and text files

### ğŸ§  YandexGPT Integration

Implemented in `src/core/llm/`:

- `client.py` â€” HTTP client for YandexGPT API

- `pipeline.py` â€” constructs messages and sends queries with document context and conversation history

### ğŸ—‚ï¸ User and History Stores

`UserStore` â€” keeps uploaded document contents per user

`HistoryStore` â€” saves the chat message history for multi-turn dialogue

## ğŸ“¦ Dependencies

**Main libraries:**
- `aiogram`
 â€” Telegram bot framework
- `httpx`
 â€” async HTTP client
- `pypdf`
 â€” PDF reader
- `python-docx`
 â€” DOCX parser
- `striprtf`
 â€” RTF to text
- `markdown`
 â€” Markdown parser
- `chardet`
 â€” encoding detection
- `pydantic-settings`
 â€” environment-based configuration

## ğŸ§­ Roadmap

Planned improvements and future development goals:

- ğŸ§© Implement document **chunking and embedding** for handling large files efficiently  
- ğŸ§± Redesign document structure and **improve internal markup parsing**  
- ğŸ—„ï¸ Develop **new storage mechanisms** for user documents  
- ğŸ‘¥ Build a robust **user session management system**  
- ğŸ“ Enable **multi-file document handling** and cross-file queries  
- ğŸ§® Add **LaTeX parsing support** for scientific and mathematical documents  
- ğŸ¤– Integrate **additional language models** (beyond YandexGPT)  
- ğŸ”— Create a **generation pipeline via LangChain** for modular, extensible response generation


 ## ğŸ‘¨â€ğŸ’» Author

**LexiBot** was developed to make document understanding conversational.
Built by **[jw-mans (Daniel Jermakiw)](https://github.com/jw-mans/)**  using Python, Aiogram, and YandexGPT.